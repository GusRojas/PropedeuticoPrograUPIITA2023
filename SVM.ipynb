{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNH3riZvI4qEdyz6EGuTjx7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ye8xtauctPHf","executionInfo":{"status":"ok","timestamp":1687833425389,"user_tz":360,"elapsed":21121,"user":{"displayName":"Gustavo Rojas","userId":"02721877199005079429"}},"outputId":"b2584035-ca05-4730-e89d-8fa647f9269a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nvz0vSD2s99Q","executionInfo":{"status":"ok","timestamp":1687835297118,"user_tz":360,"elapsed":109517,"user":{"displayName":"Gustavo Rojas","userId":"02721877199005079429"}},"outputId":"6ee8f973-d53a-41d1-9e37-12666293e7ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["reading and processing emails from file.\n","Training model.\n","FINISHED classifying. Accuracy score: 92.96%\n"]}],"source":["import os\n","import numpy as np\n","from collections import Counter\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","def make_Dictionary(root_dir):\n","   all_words = []\n","   emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n","   for mail in emails:\n","        with open(mail) as m:\n","            for line in m:\n","                words = line.split()\n","                all_words += words\n","   dictionary = Counter(all_words)\n","   # if you have python version 3.x use commented version.\n","   list_to_remove = list(dictionary.keys())\n","   #list_to_remove = dictionary.keys()\n","   for item in list_to_remove:\n","       # remove if numerical.\n","      if item.isalpha() == False:\n","        del dictionary[item]\n","      elif len(item) == 1:\n","        del dictionary[item]\n","    # consider only most 3000 common words in dictionary.\n","   dictionary = dictionary.most_common(3000)\n","   return dictionary\n","def extract_features(mail_dir):\n","    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n","    features_matrix = np.zeros((len(files),3000))\n","    train_labels = np.zeros(len(files))\n","    count = 0;\n","    docID = 0;\n","    for fil in files:\n","      with open(fil) as fi:\n","        for i,line in enumerate(fi):\n","          if i == 2:\n","            words = line.split()\n","            for word in words:\n","              wordID = 0\n","              for i,d in enumerate(dictionary):\n","                if d[0] == word:\n","                  wordID = i\n","                  features_matrix[docID,wordID] = words.count(word)\n","        train_labels[docID] = 0;\n","        filepathTokens = fil.split('/')\n","        lastToken = filepathTokens[len(filepathTokens) - 1]\n","        if lastToken.startswith(\"spmsg\"):\n","            train_labels[docID] = 1;\n","            count = count + 1\n","        docID = docID + 1\n","    return features_matrix, train_labels\n","TRAIN_DIR = \"/content/drive/MyDrive/Notas Propredeutico/Programación/train-mails\"\n","TEST_DIR = \"/content/drive/MyDrive/Notas Propredeutico/Programación/test-mails\"\n","dictionary = make_Dictionary(TRAIN_DIR)\n","print (\"reading and processing emails from file.\")\n","features_matrix, labels = extract_features(TRAIN_DIR)\n","test_feature_matrix, test_labels = extract_features(TEST_DIR)\n","model = svm.SVC()\n","print (\"Training model.\")\n","#train model\n","model.fit(features_matrix, labels)\n","predicted_labels = model.predict(test_feature_matrix)\n","accuracy=accuracy_score(test_labels, predicted_labels)\n","print(\"FINISHED classifying. Accuracy score: {:.2%}\".format(accuracy))"]}]}